{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "54291de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954092d1",
   "metadata": {},
   "source": [
    "# Planning:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aba3b37",
   "metadata": {},
   "source": [
    "- Working with Big 5 personality test data from Kaggle.\n",
    "- Want to do a clustering project to see if I can find groupings of personality 'types' based on responses.\n",
    "- Would like to see if I can create a mechanism that will allow someone to answer the questionaire and see what the model would predict their personality to be."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0b6eb8",
   "metadata": {},
   "source": [
    "# Acquire:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d4ce300",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Data From CSV (this file uses '\\t' as the delimeter, so I need to account for that):\n",
    "df = pd.read_csv('big_5_data.csv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90626872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXT1</th>\n",
       "      <th>EXT2</th>\n",
       "      <th>EXT3</th>\n",
       "      <th>EXT4</th>\n",
       "      <th>EXT5</th>\n",
       "      <th>EXT6</th>\n",
       "      <th>EXT7</th>\n",
       "      <th>EXT8</th>\n",
       "      <th>EXT9</th>\n",
       "      <th>EXT10</th>\n",
       "      <th>...</th>\n",
       "      <th>dateload</th>\n",
       "      <th>screenw</th>\n",
       "      <th>screenh</th>\n",
       "      <th>introelapse</th>\n",
       "      <th>testelapse</th>\n",
       "      <th>endelapse</th>\n",
       "      <th>IPC</th>\n",
       "      <th>country</th>\n",
       "      <th>lat_appx_lots_of_err</th>\n",
       "      <th>long_appx_lots_of_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-03-03 02:01:01</td>\n",
       "      <td>768.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>GB</td>\n",
       "      <td>51.5448</td>\n",
       "      <td>0.1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-03-03 02:01:20</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>MY</td>\n",
       "      <td>3.1698</td>\n",
       "      <td>101.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-03-03 02:01:56</td>\n",
       "      <td>1366.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>GB</td>\n",
       "      <td>54.9119</td>\n",
       "      <td>-1.3833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-03-03 02:02:02</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>GB</td>\n",
       "      <td>51.75</td>\n",
       "      <td>-1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-03-03 02:02:57</td>\n",
       "      <td>1366.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>KE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EXT1  EXT2  EXT3  EXT4  EXT5  EXT6  EXT7  EXT8  EXT9  EXT10  ...  \\\n",
       "0   4.0   1.0   5.0   2.0   5.0   1.0   5.0   2.0   4.0    1.0  ...   \n",
       "1   3.0   5.0   3.0   4.0   3.0   3.0   2.0   5.0   1.0    5.0  ...   \n",
       "2   2.0   3.0   4.0   4.0   3.0   2.0   1.0   3.0   2.0    5.0  ...   \n",
       "3   2.0   2.0   2.0   3.0   4.0   2.0   2.0   4.0   1.0    4.0  ...   \n",
       "4   3.0   3.0   3.0   3.0   5.0   3.0   3.0   5.0   3.0    4.0  ...   \n",
       "\n",
       "              dateload  screenw  screenh  introelapse  testelapse  endelapse  \\\n",
       "0  2016-03-03 02:01:01    768.0   1024.0          9.0       234.0          6   \n",
       "1  2016-03-03 02:01:20   1360.0    768.0         12.0       179.0         11   \n",
       "2  2016-03-03 02:01:56   1366.0    768.0          3.0       186.0          7   \n",
       "3  2016-03-03 02:02:02   1920.0   1200.0        186.0       219.0          7   \n",
       "4  2016-03-03 02:02:57   1366.0    768.0          8.0       315.0         17   \n",
       "\n",
       "   IPC  country  lat_appx_lots_of_err  long_appx_lots_of_err  \n",
       "0    1       GB               51.5448                 0.1991  \n",
       "1    1       MY                3.1698                101.706  \n",
       "2    1       GB               54.9119                -1.3833  \n",
       "3    1       GB                 51.75                  -1.25  \n",
       "4    2       KE                   1.0                   38.0  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "560e1cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EXT1',\n",
       " 'EXT2',\n",
       " 'EXT3',\n",
       " 'EXT4',\n",
       " 'EXT5',\n",
       " 'EXT6',\n",
       " 'EXT7',\n",
       " 'EXT8',\n",
       " 'EXT9',\n",
       " 'EXT10',\n",
       " 'EST1',\n",
       " 'EST2',\n",
       " 'EST3',\n",
       " 'EST4',\n",
       " 'EST5',\n",
       " 'EST6',\n",
       " 'EST7',\n",
       " 'EST8',\n",
       " 'EST9',\n",
       " 'EST10',\n",
       " 'AGR1',\n",
       " 'AGR2',\n",
       " 'AGR3',\n",
       " 'AGR4',\n",
       " 'AGR5',\n",
       " 'AGR6',\n",
       " 'AGR7',\n",
       " 'AGR8',\n",
       " 'AGR9',\n",
       " 'AGR10',\n",
       " 'CSN1',\n",
       " 'CSN2',\n",
       " 'CSN3',\n",
       " 'CSN4',\n",
       " 'CSN5',\n",
       " 'CSN6',\n",
       " 'CSN7',\n",
       " 'CSN8',\n",
       " 'CSN9',\n",
       " 'CSN10',\n",
       " 'OPN1',\n",
       " 'OPN2',\n",
       " 'OPN3',\n",
       " 'OPN4',\n",
       " 'OPN5',\n",
       " 'OPN6',\n",
       " 'OPN7',\n",
       " 'OPN8',\n",
       " 'OPN9',\n",
       " 'OPN10',\n",
       " 'EXT1_E',\n",
       " 'EXT2_E',\n",
       " 'EXT3_E',\n",
       " 'EXT4_E',\n",
       " 'EXT5_E',\n",
       " 'EXT6_E',\n",
       " 'EXT7_E',\n",
       " 'EXT8_E',\n",
       " 'EXT9_E',\n",
       " 'EXT10_E',\n",
       " 'EST1_E',\n",
       " 'EST2_E',\n",
       " 'EST3_E',\n",
       " 'EST4_E',\n",
       " 'EST5_E',\n",
       " 'EST6_E',\n",
       " 'EST7_E',\n",
       " 'EST8_E',\n",
       " 'EST9_E',\n",
       " 'EST10_E',\n",
       " 'AGR1_E',\n",
       " 'AGR2_E',\n",
       " 'AGR3_E',\n",
       " 'AGR4_E',\n",
       " 'AGR5_E',\n",
       " 'AGR6_E',\n",
       " 'AGR7_E',\n",
       " 'AGR8_E',\n",
       " 'AGR9_E',\n",
       " 'AGR10_E',\n",
       " 'CSN1_E',\n",
       " 'CSN2_E',\n",
       " 'CSN3_E',\n",
       " 'CSN4_E',\n",
       " 'CSN5_E',\n",
       " 'CSN6_E',\n",
       " 'CSN7_E',\n",
       " 'CSN8_E',\n",
       " 'CSN9_E',\n",
       " 'CSN10_E',\n",
       " 'OPN1_E',\n",
       " 'OPN2_E',\n",
       " 'OPN3_E',\n",
       " 'OPN4_E',\n",
       " 'OPN5_E',\n",
       " 'OPN6_E',\n",
       " 'OPN7_E',\n",
       " 'OPN8_E',\n",
       " 'OPN9_E',\n",
       " 'OPN10_E',\n",
       " 'dateload',\n",
       " 'screenw',\n",
       " 'screenh',\n",
       " 'introelapse',\n",
       " 'testelapse',\n",
       " 'endelapse',\n",
       " 'IPC',\n",
       " 'country',\n",
       " 'lat_appx_lots_of_err',\n",
       " 'long_appx_lots_of_err']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_list = list(df)\n",
    "column_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bfa01c",
   "metadata": {},
   "source": [
    "# Prepare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57af7375",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating list to drop columns that contain time to click answers, as well as screen size and latitude/longitude guesses:\n",
    "drop_columns = ['EXT1_E', 'EXT2_E', 'EXT3_E', 'EXT4_E', 'EXT5_E', 'EXT6_E', 'EXT7_E', 'EXT8_E', 'EXT9_E', 'EXT10_E', 'EST1_E', 'EST2_E', 'EST3_E', 'EST4_E', 'EST5_E', 'EST6_E', 'EST7_E', 'EST8_E', 'EST9_E', 'EST10_E', 'AGR1_E', 'AGR2_E', 'AGR3_E', 'AGR4_E', 'AGR5_E', 'AGR6_E', 'AGR7_E', 'AGR8_E', 'AGR9_E', 'AGR10_E', 'CSN1_E', 'CSN2_E', 'CSN3_E', 'CSN4_E', 'CSN5_E', 'CSN6_E', 'CSN7_E', 'CSN8_E', 'CSN9_E', 'CSN10_E', 'OPN1_E', 'OPN2_E', 'OPN3_E', 'OPN4_E', 'OPN5_E', 'OPN6_E', 'OPN7_E', 'OPN8_E', 'OPN9_E', 'OPN10_E', 'screenw', 'screenh', 'lat_appx_lots_of_err', 'long_appx_lots_of_err']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "280efc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping Unneeded Columns:\n",
    "df = df.drop(columns=drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a505b3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determining the number of null values in the data:\n",
    "df.isnull().sum()\n",
    "\n",
    "#It appears that there are, at most, 2066 nulls in the data. \n",
    "#I'm going to go ahead and drop the rows containing null values:\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b30b06c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3133876784743837"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#It appears that about 31% of the records come from non-unique IP addresses.\n",
    "df[df.IPC > 1].shape[0]/ df.shape[0]\n",
    "\n",
    "#Should I drop these for the sake of clean data, or is 31% too large of a chunk to remove?\n",
    "#Or, does the nature of a personality test kind of make it irrelevant for something like clustering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dd15188a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6866123215256164"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There would still be 694,886 records if I dropped all the duplicate IPs:\n",
    "#This would be roughly 69% of the data.\n",
    "\n",
    "df[df.IPC == 1].shape[0] / df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39574d0d",
   "metadata": {},
   "source": [
    "## Preparation Considerations:\n",
    "- Do I need to keep the following:\n",
    "    - introelapse The time in seconds spent on the landing / intro page\n",
    "    - testelapse  The time in seconds spent on the page with the survey questions\n",
    "    - endelapse   The time in seconds spent on the finalization page (where the user was asked to indicate if they has answered\n",
    "    * The only real value of this would be to see if there is a relationship between time lapse and any of the big 5. Maybe higher elapsed times indicates more neuroticism (lower on 'emotional stability')?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a113d881",
   "metadata": {},
   "source": [
    "# Exploration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8552caed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train observations:  31737888\n",
      "validate observations:  13601952\n",
      "test observations:  11334960\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data (this is the code from the curriculum - return to customize later):\n",
    "\n",
    "# split test off, 20% of original df size. \n",
    "train_validate, test = train_test_split(df, test_size=.2, \n",
    "                                        random_state=123)\n",
    "\n",
    "# split validate off, 30% of what remains (24% of original df size)\n",
    "# thus train will be 56% of original df size. \n",
    "train, validate = train_test_split(train_validate, test_size=.3, \n",
    "                                   random_state=123)\n",
    "\n",
    "print(\"train observations: \", train.size)\n",
    "print(\"validate observations: \", validate.size)\n",
    "print(\"test observations: \", test.size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
